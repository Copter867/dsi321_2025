# ğŸ“Š DSI321 Final Project

## âœ… Project Status

| **Module / Tool**                            | **Status** |
|---------------------------------------------|:----------:|
| Modern Logging (`Logging`, `Rich`)          | âœ…         |
| Web Scraping                                | âœ…         |
| Database (`LakeFS`)                         | âœ…         |
| Data Validation (`Pydantic`)                | âœ…         |
| Orchestration (`Prefect`) Part 1: All tweets| âœ…         |
| Orchestration (`Prefect`) Part 2: Only new tweets | âœ…   |
| ML (`Word Cloud`)                           | âœ…         |
| Web Interface (`Streamlit`)                 | â¬œï¸         |

---

## ğŸ—‚ï¸ Project Structure

<details>
<summary>Click to expand</summary>

â”œâ”€â”€ config
â”‚ â”œâ”€â”€ docker
â”‚ â”‚ â”œâ”€â”€ Dockerfile.cli # CLI Dockerfile
â”‚ â”‚ â””â”€â”€ Dockerfile.worker # Worker Dockerfile
â”‚ â”œâ”€â”€ logging
â”‚ â”‚ â””â”€â”€ modern_log.py # Custom logging with Rich
â”‚ â””â”€â”€ path_config.py # Paths config
â”œâ”€â”€ src
â”‚ â”œâ”€â”€ backend
â”‚ â”‚ â”œâ”€â”€ load
â”‚ â”‚ â”‚ â””â”€â”€ lakefs_loader.py # Upload to lakeFS
â”‚ â”‚ â”œâ”€â”€ pipeline
â”‚ â”‚ â”‚ â”œâ”€â”€ initial_scrape_flow.py # First-time full scrape
â”‚ â”‚ â”‚ â””â”€â”€ incremental_scrape_flow.py # 15-min scrape flow
â”‚ â”‚ â”œâ”€â”€ scraping
â”‚ â”‚ â”‚ â”œâ”€â”€ x_login.py # X login
â”‚ â”‚ â”‚ â””â”€â”€ x_scraping.py # Scraping logic
â”‚ â”‚ â””â”€â”€ validation
â”‚ â”‚ â””â”€â”€ validate.py # Pydantic data validation
â”‚ â””â”€â”€ fronend â† (typo! should be frontend)
â”‚ â””â”€â”€ streamlit.py # Streamlit dashboard
â”œâ”€â”€ test # Test files
â”œâ”€â”€ .env.example # Env variable example
â”œâ”€â”€ .gitignore # Git ignore
â”œâ”€â”€ README.md # Documentation
â”œâ”€â”€ docker-compose.yml # Docker Compose setup
â”œâ”€â”€ pyproject.toml # Poetry/Project config
â”œâ”€â”€ requirements.txt # Required Python packages
â””â”€â”€ start.sh # Startup script
